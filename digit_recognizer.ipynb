{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22e7fbfeda0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show an example image from the training data along with its label\n",
    "index = int(random.random()*len(x_train))\n",
    "print(y_train[index])\n",
    "plt.imshow(x_train[index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 60k training examples, 28 x 28 pixel images\n",
    "print(x_train.shape)\n",
    "# 10k testing examples\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape, only one layer (grayscale)\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model - convolution, pooling, flatten, relu, dropout, softmax\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape = input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1975 - accuracy: 0.9414\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0827 - accuracy: 0.9743\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0551 - accuracy: 0.9826\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0413 - accuracy: 0.9870\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0327 - accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22f4bffbdd8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 74us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.053561915939213944, 0.9830999970436096]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretty much the same despite having twice as many neurons in the second to last layer\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2\n",
      "Actual: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22f4face860>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show an example image from the training data along with its label\n",
    "# and its predicted label from the model\n",
    "index = int(random.random()*len(x_test))\n",
    "pred = model.predict(x_test[index].reshape(1, 28, 28, 1))\n",
    "print('Prediction: {}'.format(pred.argmax()))\n",
    "print('Actual: {}'.format(y_test[index]))\n",
    "plt.imshow(x_test[index].reshape(28, 28), cmap='Greys')\n",
    "# Looks like a 1 to me..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.0252 - accuracy: 0.9912\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0234 - accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# Verify CUDA installation and compare GPU training speed to CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x=x_train, y=y_train, epochs=1)\n",
    "with tf.device('/GPU:0'):\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "    model.fit(x=x_train, y=y_train, epochs=1)\n",
    "# I don't have a great GPU, but it's better than nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try some different architectures\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape, padding='same', activation=tf.nn.relu))\n",
    "model2.add(Conv2D(64, kernel_size=(3,3), padding='same', activation=tf.nn.relu))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation=tf.nn.relu))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.5017 - accuracy: 0.8469\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1613 - accuracy: 0.9537\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1194 - accuracy: 0.9651\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0991 - accuracy: 0.9695\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0839 - accuracy: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22f544eeef0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', \n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "model2.fit(x=x_train, y=y_train, epochs=5, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 142us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03603210315018077, 0.9883999824523926]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Barely better\n",
    "model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dropout(0.1))\n",
    "model3.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape, padding='same', activation=tf.nn.relu))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Conv2D(32, kernel_size=(3,3), padding='same', activation=tf.nn.relu))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(64, activation=tf.nn.relu))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0795 - accuracy: 0.9755\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0707 - accuracy: 0.9783\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0639 - accuracy: 0.9800\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0578 - accuracy: 0.9819\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0532 - accuracy: 0.9829\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0469 - accuracy: 0.9853\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0440 - accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0413 - accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0390 - accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0383 - accuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22f558f57b8>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model3.fit(x=x_train, y=y_train, epochs=10, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 106us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.028460302224976475, 0.9907000064849854]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This one was much faster, and slightly better.\n",
    "model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
