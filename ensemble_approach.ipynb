{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ran in colab, because my computer is not strong enough.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization, Add, Activation, Cropping2D, Concatenate\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetUnit(x, filters=64, size=3, activation='relu', padding='same'):\n",
    "    y = Conv2D(filters, size, activation=activation, padding=padding)(x)\n",
    "    #y = BatchNormalization()(y)\n",
    "    y = Conv2D(filters, size, activation=None, padding=padding)(y)\n",
    "    #y = BatchNormalization()(y)\n",
    "    if padding=='same':\n",
    "        y = Add()([x, y])\n",
    "    else:\n",
    "        x = Cropping2D(size-1)(x)\n",
    "        y = Add()([x, y])\n",
    "    y = Activation(activation)(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, batch_size, epochs):\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = Conv2D(64, 3, activation='relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    for _ in range(8):\n",
    "        x = ResNetUnit(x)\n",
    "    x = Conv2D(64, 3, activation='relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    return model\n",
    "\n",
    "# For testing\n",
    "def train_simple_model(x_train, y_train, batch_size, epochs):\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = Conv2D(64, 3, activation='relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = ResNetUnit(x)\n",
    "    x = Conv2D(64, 3, activation='relu')(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('digit-recognizer/train.csv')\n",
    "data_x = np.array(df.drop('label', axis=1))\n",
    "data_y = np.array(df['label'])\n",
    "data_test  = np.array(pd.read_csv('digit-recognizer/test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_x.reshape(42000, 28, 28, 1).astype('float32')\n",
    "data_test = data_test.reshape(28000, 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x /= 255.0\n",
    "data_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(n, batch_size, epochs):\n",
    "    #with tf.device('/GPU:0'):\n",
    "    models = []\n",
    "    total = data_x.shape[0]\n",
    "    all_inds = np.arange(data_x.shape[0])\n",
    "    dist = np.repeat(1, data_x.shape[0])\n",
    "    for i in range(n):\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        if i == 0:\n",
    "            # First run uses all samples\n",
    "            train_x = data_x\n",
    "            train_y = data_y\n",
    "        else:\n",
    "            # Next runs weight samples more if they came up as errors\n",
    "            inds = np.random.choice(all_inds, data_x.shape[0], replace=False, p=dist/total)\n",
    "            train_x = data_x[inds]\n",
    "            train_y = data_y[inds]\n",
    "        print('Training model', i)\n",
    "        # Todo: simple model for debug...\n",
    "        model = train_model(train_x, train_y, batch_size, epochs)\n",
    "        print('Making predictions')\n",
    "        raw_pred = model.predict(train_x) # Batch size has to match for this to work, apparently.\n",
    "        #print(raw_pred[0:10])\n",
    "        pred = np.argmax(raw_pred, axis=1)\n",
    "        #print(pred[0:10])\n",
    "        errors = np.not_equal(pred, train_y)\n",
    "        #print(train_y[0:10])\n",
    "        print('Model {0} accuracy is {1:.3f}'.format(i, 100*(1-np.sum(errors)/train_y.shape[0])))\n",
    "        dist += errors\n",
    "        total += sum(errors)\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ensemble(models, train_x, train_y):\n",
    "    raw_preds = np.zeros((train_x.shape[0], 10))\n",
    "    for i in range(len(models)):\n",
    "        print('Making prediction', i)\n",
    "        raw_preds += models[i].predict(train_x)\n",
    "    preds = np.argmax(raw_preds, axis=1)\n",
    "    errors = np.not_equal(preds, train_y)\n",
    "    print('Ensemble accuracy is {:.3f}'.format(100*(1 - np.sum(errors)/train_y.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = train_ensemble(10, 1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would take forever to cross-validate (it already takes forever to run in the first place)\n",
    "# This is accuracy on the training dataset, just to verify that the ensembles are helping\n",
    "check_ensemble(models, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test predictions\n",
    "raw_preds = np.zeros((data_test.shape[0], 10))\n",
    "for i in range(len(models)):\n",
    "  print('Making prediction', i)\n",
    "  raw_preds += models[i].predict(data_test)\n",
    "preds = np.argmax(raw_preds, axis=1)\n",
    "print('Prediction complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i in range(1,data_test.shape[0]+1)]\n",
    "answers = pd.DataFrame(zip(index, preds), columns=['ImageID', 'Label'])\n",
    "answers.to_csv('submission_dtree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    print('Saving model', i)\n",
    "    models[i].save('rescnn_ensemble_model'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result: 99.585% on Kaggle test data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
